============================= test session starts ==============================
platform darwin -- Python 3.12.8, pytest-8.4.1, pluggy-1.6.0 -- /Users/adam/Library/Application Support/hatch/env/virtual/claif-gem/zEC_JZp1/hatch-test.py3.12/bin/python3
cachedir: .pytest_cache
rootdir: /Users/adam/Developer/vcs/github.twardoch/pub/claif-packages/claif_gem
configfile: pyproject.toml
plugins: anyio-4.9.0, xdist-3.8.0, rerunfailures-14.0, mock-3.14.1
collecting ... collected 117 items

tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_basic FAILED  [  0%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_with_all_options FAILED [  1%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_json_format FAILED [  2%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_with_metrics FAILED [  3%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_error_handling FAILED [  4%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_with_images FAILED [  5%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_health_success FAILED [  5%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_health_failure FAILED [  6%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_models FAILED       [  7%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_config_show FAILED  [  8%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_config_set PASSED   [  9%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_install FAILED      [ 10%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_install_failure FAILED [ 11%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_status PASSED       [ 11%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_stream FAILED       [ 12%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_benchmark FAILED    [ 13%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_process_images_local_files FAILED [ 14%]
tests/test_cli_comprehensive.py::TestGeminiCLI::test_process_images_urls FAILED [ 15%]
tests/test_cli_comprehensive.py::TestMainFunction::test_main PASSED      [ 16%]
tests/test_cli_comprehensive.py::TestMainFunction::test_main_with_args PASSED [ 17%]
tests/test_client_comprehensive.py::TestHelperFunctions::test_is_cli_missing_error FAILED [ 17%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_success FAILED [ 18%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_no_options FAILED [ 19%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_with_error_result FAILED [ 20%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_multiple_messages FAILED [ 21%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_auto_install_on_cli_missing FAILED [ 22%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_auto_install_fails FAILED [ 23%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_non_cli_error FAILED [ 23%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_ensures_disconnect FAILED [ 24%]
tests/test_client_comprehensive.py::TestGeminiClient::test_query_connect_error FAILED [ 25%]
tests/test_client_comprehensive.py::TestModuleLevelFunctions::test_get_client_singleton PASSED [ 26%]
tests/test_client_comprehensive.py::TestModuleLevelFunctions::test_query_function FAILED [ 27%]
tests/test_client_comprehensive.py::TestModuleLevelFunctions::test_query_function_with_options FAILED [ 28%]
tests/test_install_comprehensive.py::TestInstallGeminiBundled::test_install_success PASSED [ 29%]
tests/test_install_comprehensive.py::TestInstallGeminiBundled::test_install_source_not_found PASSED [ 29%]
tests/test_install_comprehensive.py::TestInstallGeminiBundled::test_install_copy_exception PASSED [ 30%]
tests/test_install_comprehensive.py::TestInstallGemini::test_install_bun_failure PASSED [ 31%]
tests/test_install_comprehensive.py::TestInstallGemini::test_install_npm_failure PASSED [ 32%]
tests/test_install_comprehensive.py::TestInstallGemini::test_install_bundle_failure PASSED [ 33%]
tests/test_install_comprehensive.py::TestInstallGemini::test_install_success PASSED [ 34%]
tests/test_install_comprehensive.py::TestInstallGemini::test_install_bundled_failure PASSED [ 35%]
tests/test_install_comprehensive.py::TestUninstallGemini::test_uninstall_success PASSED [ 35%]
tests/test_install_comprehensive.py::TestUninstallGemini::test_uninstall_failure PASSED [ 36%]
tests/test_install_comprehensive.py::TestIsGeminiInstalled::test_installed_as_file PASSED [ 37%]
tests/test_install_comprehensive.py::TestIsGeminiInstalled::test_installed_as_directory PASSED [ 38%]
tests/test_install_comprehensive.py::TestIsGeminiInstalled::test_not_installed PASSED [ 39%]
tests/test_install_comprehensive.py::TestGetGeminiStatus::test_status_installed PASSED [ 40%]
tests/test_install_comprehensive.py::TestGetGeminiStatus::test_status_not_installed PASSED [ 41%]
tests/test_package.py::test_version PASSED                               [ 41%]
tests/test_package.py::TestGeminiTransport::test_initialization PASSED   [ 42%]
tests/test_package.py::TestGeminiTransport::test_build_command_simple PASSED [ 43%]
tests/test_package.py::TestGeminiTransport::test_build_command_with_options PASSED [ 44%]
tests/test_package.py::TestGeminiTransport::test_build_command_with_script PASSED [ 45%]
tests/test_package.py::TestGeminiTransport::test_find_cli_raises_error PASSED [ 46%]
tests/test_package.py::TestGeminiTransport::test_send_query_success FAILED [ 47%]
tests/test_package.py::TestGeminiTransport::test_send_query_with_retry FAILED [ 47%]
tests/test_package.py::TestGeminiTransport::test_send_query_all_retries_fail FAILED [ 48%]
tests/test_retry_logic.py::test_retry_on_quota_exhausted FAILED          [ 49%]
tests/test_retry_logic.py::test_retry_on_rate_limit FAILED               [ 50%]
tests/test_retry_logic.py::test_no_retry_flag FAILED                     [ 51%]
tests/test_retry_logic.py::test_max_retries_exceeded FAILED              [ 52%]
tests/test_retry_logic.py::test_non_retryable_error FAILED               [ 52%]
tests/test_transport.py::test_send_query_success FAILED                  [ 53%]
tests/test_transport.py::test_build_command_verbose FAILED               [ 54%]
tests/test_transport.py::test_build_command_model FAILED                 [ 55%]
tests/test_transport.py::test_build_command_temperature FAILED           [ 56%]
tests/test_transport.py::test_build_command_system_prompt FAILED         [ 57%]
tests/test_transport.py::test_build_command_max_context_length FAILED    [ 58%]
tests/test_transport.py::test_build_command_auto_approve FAILED          [ 58%]
tests/test_transport.py::test_build_command_yes_mode FAILED              [ 59%]
tests/test_transport.py::test_send_query_cli_error FAILED                [ 60%]
tests/test_transport.py::test_send_query_json_decode_error FAILED        [ 61%]
tests/test_transport.py::test_disconnect_terminates_process FAILED       [ 62%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_init PASSED [ 63%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_connect FAILED [ 64%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_disconnect_no_process FAILED [ 64%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_disconnect_with_process FAILED [ 65%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_disconnect_with_error FAILED [ 66%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_command_minimal PASSED [ 67%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_command_with_all_options PASSED [ 68%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_command_no_auto_approve PASSED [ 69%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_command_with_shell_script PASSED [ 70%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_env FAILED [ 70%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_env_import_error FAILED [ 71%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_find_cli_success PASSED [ 72%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_find_cli_with_exec_path PASSED [ 73%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_find_cli_error PASSED [ 74%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_success_json FAILED [ 75%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_success_plain_text FAILED [ 76%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_error_non_retryable FAILED [ 76%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_error_retryable FAILED [ 77%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_empty_response FAILED [ 78%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_no_retry FAILED [ 79%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_with_retry_success FAILED [ 80%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_all_retries_fail FAILED [ 81%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_empty_response_error FAILED [ 82%]
tests/test_transport_comprehensive.py::TestGeminiTransport::test_process_tracking FAILED [ 82%]
tests/test_types_comprehensive.py::TestGeminiOptions::test_default_options PASSED [ 83%]
tests/test_types_comprehensive.py::TestGeminiOptions::test_custom_options PASSED [ 84%]
tests/test_types_comprehensive.py::TestGeminiOptions::test_cwd_with_path_object PASSED [ 85%]
tests/test_types_comprehensive.py::TestGeminiOptions::test_partial_options PASSED [ 86%]
tests/test_types_comprehensive.py::TestGeminiMessage::test_message_creation_defaults PASSED [ 87%]
tests/test_types_comprehensive.py::TestGeminiMessage::test_message_creation_custom_role PASSED [ 88%]
tests/test_types_comprehensive.py::TestGeminiMessage::test_to_claif_message_assistant PASSED [ 88%]
tests/test_types_comprehensive.py::TestGeminiMessage::test_to_claif_message_user PASSED [ 89%]
tests/test_types_comprehensive.py::TestGeminiMessage::test_to_claif_message_unknown_role PASSED [ 90%]
tests/test_types_comprehensive.py::TestGeminiMessage::test_empty_content PASSED [ 91%]
tests/test_types_comprehensive.py::TestGeminiResponse::test_response_creation_minimal FAILED [ 92%]
tests/test_types_comprehensive.py::TestGeminiResponse::test_response_creation_full FAILED [ 93%]
tests/test_types_comprehensive.py::TestGeminiResponse::test_to_claif_message_assistant PASSED [ 94%]
tests/test_types_comprehensive.py::TestGeminiResponse::test_to_claif_message_user PASSED [ 94%]
tests/test_types_comprehensive.py::TestGeminiResponse::test_to_claif_message_preserves_content_only PASSED [ 95%]
tests/test_types_comprehensive.py::TestResultMessage::test_result_message_defaults PASSED [ 96%]
tests/test_types_comprehensive.py::TestResultMessage::test_result_message_success PASSED [ 97%]
tests/test_types_comprehensive.py::TestResultMessage::test_result_message_error PASSED [ 98%]
tests/test_types_comprehensive.py::TestResultMessage::test_result_message_minimal_error PASSED [ 99%]
tests/test_types_comprehensive.py::TestResultMessage::test_result_message_type_immutable PASSED [100%]

=================================== FAILURES ===================================
________________________ TestGeminiCLI.test_query_basic ________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.726 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
__________________ TestGeminiCLI.test_query_with_all_options ___________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.733 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
_____________________ TestGeminiCLI.test_query_json_format _____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.738 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
____________________ TestGeminiCLI.test_query_with_metrics _____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.742 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
___________________ TestGeminiCLI.test_query_error_handling ____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.747 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
_____________________ TestGeminiCLI.test_query_with_images _____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.753 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
______________________ TestGeminiCLI.test_health_success _______________________

self = <MagicMock name='_print_success' id='4602751376'>
args = ('Gemini service is healthy',), kwargs = {}
expected = call('Gemini service is healthy')
actual = call('Gemini service is healthy and responding.')
_error_message = <function NonCallableMock.assert_called_with.<locals>._error_message at 0x112333380>
cause = None

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                    % (expected, actual))
            raise AssertionError(error_message)
    
        def _error_message():
            msg = self._format_mock_failure_message(args, kwargs)
            return msg
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        actual = self._call_matcher(self.call_args)
        if actual != expected:
            cause = expected if isinstance(expected, Exception) else None
>           raise AssertionError(_error_message()) from cause
E           AssertionError: expected call not found.
E           Expected: _print_success('Gemini service is healthy')
E             Actual: _print_success('Gemini service is healthy and responding.')

/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:949: AssertionError

During handling of the above exception, another exception occurred:

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124ed0a0>
cli = <claif_gem.cli.GeminiCLI object at 0x1125854f0>

    def test_health_success(self, cli):
        """Test health check when service is healthy."""
        with patch.object(cli, "_health_check", new_callable=AsyncMock) as mock_health:
            mock_health.return_value = True
    
            with patch("claif_gem.cli._print_success") as mock_print_success:
                cli.health()
>               mock_print_success.assert_called_with("Gemini service is healthy")
E               AssertionError: expected call not found.
E               Expected: _print_success('Gemini service is healthy')
E                 Actual: _print_success('Gemini service is healthy and responding.')
E               
E               pytest introspection follows:
E               
E               Args:
E               assert ('Gemini serv...responding.',) == ('Gemini service is healthy',)
E                 
E                 At index 0 diff: 'Gemini service is healthy and responding.' != 'Gemini service is healthy'
E                 
E                 Full diff:
E                   (
E                 -     'Gemini service is healthy',
E                 +     'Gemini service is healthy and responding.',
E                 ?                               ++++++++++++++++
E                   )

tests/test_cli_comprehensive.py:180: AssertionError
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.757 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
----------------------------- Captured stdout call -----------------------------
Checking Gemini service health...
______________________ TestGeminiCLI.test_health_failure _______________________

self = <MagicMock name='_print_error' id='4602515616'>
args = ('Gemini service is not responding',), kwargs = {}
expected = call('Gemini service is not responding')
actual = call('Gemini service is not responding or health check failed.')
_error_message = <function NonCallableMock.assert_called_with.<locals>._error_message at 0x112517060>
cause = None

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                    % (expected, actual))
            raise AssertionError(error_message)
    
        def _error_message():
            msg = self._format_mock_failure_message(args, kwargs)
            return msg
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        actual = self._call_matcher(self.call_args)
        if actual != expected:
            cause = expected if isinstance(expected, Exception) else None
>           raise AssertionError(_error_message()) from cause
E           AssertionError: expected call not found.
E           Expected: _print_error('Gemini service is not responding')
E             Actual: _print_error('Gemini service is not responding or health check failed.')

/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:949: AssertionError

During handling of the above exception, another exception occurred:

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124ed1c0>
cli = <claif_gem.cli.GeminiCLI object at 0x11254c800>

    def test_health_failure(self, cli):
        """Test health check when service is not healthy."""
        with patch.object(cli, "_health_check", new_callable=AsyncMock) as mock_health:
            mock_health.return_value = False
    
            with patch("claif_gem.cli._print_error") as mock_print_error:
                with pytest.raises(SystemExit):
                    cli.health()
>               mock_print_error.assert_called_with("Gemini service is not responding")
E               AssertionError: expected call not found.
E               Expected: _print_error('Gemini service is not responding')
E                 Actual: _print_error('Gemini service is not responding or health check failed.')
E               
E               pytest introspection follows:
E               
E               Args:
E               assert ('Gemini serv...eck failed.',) == ('Gemini serv... responding',)
E                 
E                 At index 0 diff: 'Gemini service is not responding or health check failed.' != 'Gemini service is not responding'
E                 
E                 Full diff:
E                   (
E                 -     'Gemini service is not responding',
E                 +     'Gemini service is not responding or health check failed.',
E                 ?                                      ++++++++++++++++++++++++
E                   )

tests/test_cli_comprehensive.py:190: AssertionError
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.866 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
----------------------------- Captured stdout call -----------------------------
Checking Gemini service health...
__________________________ TestGeminiCLI.test_models ___________________________

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124ed2e0>
cli = <claif_gem.cli.GeminiCLI object at 0x1125852b0>

    def test_models(self, cli):
        """Test models command."""
        with patch("claif_gem.cli._print") as mock_print:
            cli.models()
    
            # Should print available models
            mock_print.assert_any_call("Available Gemini Models:")
            # Check that models are printed
            calls = [str(call[0][0]) for call in mock_print.call_args_list]
            assert any("gemini-pro" in call for call in calls)
>           assert any("gemini-flash" in call for call in calls)
E           assert False
E            +  where False = any(<generator object TestGeminiCLI.test_models.<locals>.<genexpr> at 0x112528ee0>)

tests/test_cli_comprehensive.py:202: AssertionError
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.924 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
________________________ TestGeminiCLI.test_config_show ________________________

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124ed400>
cli = <claif_gem.cli.GeminiCLI object at 0x112584bc0>

    def test_config_show(self, cli):
        """Test config show action."""
        with patch("claif_gem.cli._print") as mock_print:
            cli.config(action="show")
    
            # Should print configuration
            mock_print.assert_any_call("Gemini Configuration:")
            # Check that config values are printed
            calls = [str(call[0][0]) for call in mock_print.call_args_list]
>           assert any("Environment:" in call for call in calls)
E           assert False
E            +  where False = any(<generator object TestGeminiCLI.test_config_show.<locals>.<genexpr> at 0x112528790>)

tests/test_cli_comprehensive.py:213: AssertionError
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.934 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
__________________________ TestGeminiCLI.test_install __________________________

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124ed550>
cli = <claif_gem.cli.GeminiCLI object at 0x1125e1790>

    def test_install(self, cli):
        """Test install command."""
>       with patch("claif_gem.cli.install_gemini") as mock_install:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_cli_comprehensive.py:228: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x1125e2b40>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'claif_gem.cli' from '/Users/adam/Developer/vcs/github.twardoch/pub/claif-packages/claif_gem/src/claif_gem/cli.py'> does not have the attribute 'install_gemini'

/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1437: AttributeError
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:08.947 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
______________________ TestGeminiCLI.test_install_failure ______________________

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124ed280>
cli = <claif_gem.cli.GeminiCLI object at 0x112582660>

    def test_install_failure(self, cli):
        """Test install command failure."""
>       with patch("claif_gem.cli.install_gemini") as mock_install:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_cli_comprehensive.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x112580050>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'claif_gem.cli' from '/Users/adam/Developer/vcs/github.twardoch/pub/claif-packages/claif_gem/src/claif_gem/cli.py'> does not have the attribute 'install_gemini'

/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1437: AttributeError
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:09.017 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
__________________________ TestGeminiCLI.test_stream ___________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:09.087 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
_________________________ TestGeminiCLI.test_benchmark _________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:09.091 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
________________ TestGeminiCLI.test_process_images_local_files _________________

self = <claif_gem.cli.GeminiCLI object at 0x1125e1d90>, prompt = 'Analyze this'
model = None, temperature = None, system = None, auto_approve = True
yes_mode = True, max_context = None, timeout = None, output_format = 'text'
show_metrics = False, images = '/home/user/image.png,/data/photo.jpg'
exec = None, no_retry = False

    def query(
        self,
        prompt: str,
        model: str | None = None,
        temperature: float | None = None,
        system: str | None = None,
        auto_approve: bool = True,
        yes_mode: bool = True,
        max_context: int | None = None,
        timeout: int | None = None,
        output_format: str = "text",
        show_metrics: bool = False,
        images: str | None = None,
        exec: str | None = None,
        no_retry: bool = False,
    ) -> None:
        """
        Executes a query to the Gemini LLM and displays the response.
    
        This method orchestrates the entire query process, including option parsing,
        image processing, asynchronous execution, and result formatting.
    
        Args:
            prompt: The textual prompt to send to the Gemini model.
            model: Optional. The specific Gemini model to use (e.g., 'gemini-pro').
            temperature: Optional. Controls the randomness of the output (0.0 to 1.0).
            system: Optional. A system-level prompt to guide the model's behavior.
            auto_approve: If True, automatically approves actions without user confirmation.
            yes_mode: If True, forces 'yes' to all confirmation prompts.
            max_context: Optional. The maximum context length for the model in tokens.
            timeout: Optional. Maximum time in seconds to wait for a response.
            output_format: The desired format for the output ('text' or 'json').
            show_metrics: If True, displays performance metrics of the query.
            images: Optional. A comma-separated string of local image paths or URLs.
                    URLs will be downloaded to temporary files.
            exec: Optional. Explicit path to the Gemini CLI executable or a command
                  (e.g., 'bun run'). If None, the executable is searched in PATH.
            no_retry: If True, disables all retry attempts for the query.
        """
        # Initialize image paths to None; it will be populated if 'images' argument is provided.
        image_paths: list[str] | None = None
        if images:
            # Process the comma-separated image string into a list of paths.
            image_paths = process_images(images)
    
        # Create a GeminiOptions object from the provided arguments and configuration.
        options: GeminiOptions = GeminiOptions(
            model=model,
            temperature=temperature,
            system_prompt=system,
            auto_approve=auto_approve,
            yes_mode=yes_mode,
            max_context_length=max_context,
            timeout=timeout,
            verbose=self._config.verbose,  # Inherit verbose setting from CLI config
            images=image_paths,
            exec_path=exec,
            no_retry=no_retry,
        )
    
        start_time: float = time.time()  # Record the start time for metrics calculation.
    
        try:
            # Execute the asynchronous query and collect all messages.
>           messages: list[Message] = asyncio.run(self._query_async(prompt, options))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

src/claif_gem/cli.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py:194: in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py:118: in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:686: in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
src/claif_gem/cli.py:150: in _query_async
    async for message in query(prompt, options):
src/claif_gem/client.py:118: in query
    async for message in client.query(prompt, options):
src/claif_gem/client.py:95: in query
    raise e
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <claif_gem.client.GeminiClient object at 0x1125e0710>
prompt = 'Analyze this'
options = GeminiOptions(auto_approve=True, yes_mode=True, cwd=None, system_prompt=None, max_context_length=None, temperature=Non... exec_path=None, images=['/resolved/image.png', '/resolved/photo.jpg'], retry_count=3, retry_delay=1.0, no_retry=False)

    async def query(
        self,
        prompt: str,
        options: GeminiOptions | None = None,
    ) -> AsyncIterator[Message]:
        """Query Gemini and yield messages with auto-install on missing tools."""
        if options is None:
            options = GeminiOptions()
    
        logger.debug(f"Querying Gemini with prompt: {prompt[:100]}...")
    
        try:
            await self.transport.connect()
    
            async for response in self.transport.send_query(prompt, options):
                if isinstance(response, GeminiMessage):
                    yield response.to_claif_message()
                elif isinstance(response, ResultMessage) and response.error:
                    logger.error(f"Gemini error: {response.message}")
>                   raise Exception(response.message)
E                   Exception: Gemini CLI error: Options:
E                     -m, --model                    Model      [string] [default: "gemini-2.5-pro"]
E                     -p, --prompt                   Prompt. Appended to input on stdin (if any).
E                                                                                           [string]
E                     -s, --sandbox                  Run in sandbox?                       [boolean]
E                         --sandbox-image            Sandbox image URI.                     [string]
E                     -d, --debug                    Run in debug mode?   [boolean] [default: false]
E                     -a, --all_files                Include ALL files in context?
E                                                                         [boolean] [default: false]
E                         --show_memory_usage        Show memory usage in status bar
E                                                                         [boolean] [default: false]
E                     -y, --yolo                     Automatically accept all actions (aka YOLO
E                                                    mode, see
E                                                    https://www.youtube.com/watch?v=xvFZjo5PgG0 for
E                                                    more details)?       [boolean] [default: false]
E                         --telemetry                Enable telemetry? This flag specifically
E                                                    controls if telemetry is sent. Other
E                                                    --telemetry-* flags set specific values but do
E                                                    not enable telemetry on their own.    [boolean]
E                         --telemetry-target         Set the telemetry target (local or gcp).
E                                                    Overrides settings files.
E                                                                 [string] [choices: "local", "gcp"]
E                         --telemetry-otlp-endpoint  Set the OTLP endpoint for telemetry. Overrides
E                                                    environment variables and settings files.
E                                                                                           [string]
E                         --telemetry-log-prompts    Enable or disable logging of user prompts for
E                                                    telemetry. Overrides settings files.  [boolean]
E                     -c, --checkpointing            Enables checkpointing of file edits
E                                                                         [boolean] [default: false]
E                     -v, --version                  Show version number                   [boolean]
E                     -h, --help                     Show help                             [boolean]
E                   Unknown argument: i

src/claif_gem/client.py:58: Exception

During handling of the above exception, another exception occurred:

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124ed9d0>
cli = <claif_gem.cli.GeminiCLI object at 0x1125e1d90>

    def test_process_images_local_files(self, cli):
        """Test process_images with local files."""
        with patch("claif_gem.cli.process_images") as mock_process_images:
            mock_process_images.return_value = ["/resolved/image.png", "/resolved/photo.jpg"]
    
>           cli.query("Analyze this", images="/home/user/image.png,/data/photo.jpg")

tests/test_cli_comprehensive.py:301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <claif_gem.cli.GeminiCLI object at 0x1125e1d90>, prompt = 'Analyze this'
model = None, temperature = None, system = None, auto_approve = True
yes_mode = True, max_context = None, timeout = None, output_format = 'text'
show_metrics = False, images = '/home/user/image.png,/data/photo.jpg'
exec = None, no_retry = False

    def query(
        self,
        prompt: str,
        model: str | None = None,
        temperature: float | None = None,
        system: str | None = None,
        auto_approve: bool = True,
        yes_mode: bool = True,
        max_context: int | None = None,
        timeout: int | None = None,
        output_format: str = "text",
        show_metrics: bool = False,
        images: str | None = None,
        exec: str | None = None,
        no_retry: bool = False,
    ) -> None:
        """
        Executes a query to the Gemini LLM and displays the response.
    
        This method orchestrates the entire query process, including option parsing,
        image processing, asynchronous execution, and result formatting.
    
        Args:
            prompt: The textual prompt to send to the Gemini model.
            model: Optional. The specific Gemini model to use (e.g., 'gemini-pro').
            temperature: Optional. Controls the randomness of the output (0.0 to 1.0).
            system: Optional. A system-level prompt to guide the model's behavior.
            auto_approve: If True, automatically approves actions without user confirmation.
            yes_mode: If True, forces 'yes' to all confirmation prompts.
            max_context: Optional. The maximum context length for the model in tokens.
            timeout: Optional. Maximum time in seconds to wait for a response.
            output_format: The desired format for the output ('text' or 'json').
            show_metrics: If True, displays performance metrics of the query.
            images: Optional. A comma-separated string of local image paths or URLs.
                    URLs will be downloaded to temporary files.
            exec: Optional. Explicit path to the Gemini CLI executable or a command
                  (e.g., 'bun run'). If None, the executable is searched in PATH.
            no_retry: If True, disables all retry attempts for the query.
        """
        # Initialize image paths to None; it will be populated if 'images' argument is provided.
        image_paths: list[str] | None = None
        if images:
            # Process the comma-separated image string into a list of paths.
            image_paths = process_images(images)
    
        # Create a GeminiOptions object from the provided arguments and configuration.
        options: GeminiOptions = GeminiOptions(
            model=model,
            temperature=temperature,
            system_prompt=system,
            auto_approve=auto_approve,
            yes_mode=yes_mode,
            max_context_length=max_context,
            timeout=timeout,
            verbose=self._config.verbose,  # Inherit verbose setting from CLI config
            images=image_paths,
            exec_path=exec,
            no_retry=no_retry,
        )
    
        start_time: float = time.time()  # Record the start time for metrics calculation.
    
        try:
            # Execute the asynchronous query and collect all messages.
            messages: list[Message] = asyncio.run(self._query_async(prompt, options))
    
            # Iterate through the received messages and format/display them.
            for message in messages:
                formatted_output: str = format_response(message, output_format)
                _print(formatted_output)
    
            # If requested, calculate and display response metrics.
            if show_metrics:
                duration: float = time.time() - start_time
                metrics: ResponseMetrics = ResponseMetrics(
                    duration=duration,
                    provider=Provider.GEMINI,
                    model=model or "default",  # Use "default" if no specific model was provided.
                )
                _print("\n" + format_metrics(metrics))
    
        except Exception as e:
            # Catch any exceptions during the query process, print an error message,
            # and exit with a non-zero status code to indicate failure.
            _print_error(str(e))
            if self._config.verbose:
                # If verbose mode is enabled, print the full traceback for debugging.
                logger.exception("Full error details for Gemini query failure:")
>           sys.exit(1)
E           SystemExit: 1

src/claif_gem/cli.py:136: SystemExit
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:09.096 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
----------------------------- Captured stdout call -----------------------------
Error: Gemini CLI error: Options:
  -m, --model                    Model       
  -p, --prompt                   Prompt. Appended to input on stdin (if any).
                                                                        
  -s, --sandbox                  Run in sandbox?                       
      --sandbox-image            Sandbox image URI.                     
  -d, --debug                    Run in debug mode?    
  -a, --all_files                Include ALL files in context?
                                                       
      --show_memory_usage        Show memory usage in status bar
                                                       
  -y, --yolo                     Automatically accept all actions (aka YOLO
                                 mode, see
                                 https://www.youtube.com/watch?v=xvFZjo5PgG0 for
                                 more details)?        
      --telemetry                Enable telemetry? This flag specifically
                                 controls if telemetry is sent. Other
                                 --telemetry-* flags set specific values but do
                                 not enable telemetry on their own.    
      --telemetry-target         Set the telemetry target (local or gcp).
                                 Overrides settings files.
                                               
      --telemetry-otlp-endpoint  Set the OTLP endpoint for telemetry. Overrides
                                 environment variables and settings files.
                                                                        
      --telemetry-log-prompts    Enable or disable logging of user prompts for
                                 telemetry. Overrides settings files.  
  -c, --checkpointing            Enables checkpointing of file edits
                                                       
  -v, --version                  Show version number                   
  -h, --help                     Show help                             
Unknown argument: i
----------------------------- Captured stderr call -----------------------------
2025-07-03 18:14:09.096 | DEBUG    | claif_gem.client:query:48 - Querying Gemini with prompt: Analyze this...
2025-07-03 18:14:09.097 | DEBUG    | claif.install:get_install_location:47 - Using claif install directory: /Users/adam/Library/Application Support/com.twardoch.claif/bin
2025-07-03 18:14:09.097 | DEBUG    | claif.common.utils:inject_claif_bin_to_path:313 - Injected /Users/adam/Library/Application Support/com.twardoch.claif/bin into PATH.
2025-07-03 18:14:09.097 | DEBUG    | claif_gem.transport:send_query:152 - Gemini query attempt 1/3
2025-07-03 18:14:10.346 | ERROR    | claif_gem.client:query:57 - Gemini error: Gemini CLI error: Options:
  -m, --model                    Model      [string] [default: "gemini-2.5-pro"]
  -p, --prompt                   Prompt. Appended to input on stdin (if any).
                                                                        [string]
  -s, --sandbox                  Run in sandbox?                       [boolean]
      --sandbox-image            Sandbox image URI.                     [string]
  -d, --debug                    Run in debug mode?   [boolean] [default: false]
  -a, --all_files                Include ALL files in context?
                                                      [boolean] [default: false]
      --show_memory_usage        Show memory usage in status bar
                                                      [boolean] [default: false]
  -y, --yolo                     Automatically accept all actions (aka YOLO
                                 mode, see
                                 https://www.youtube.com/watch?v=xvFZjo5PgG0 for
                                 more details)?       [boolean] [default: false]
      --telemetry                Enable telemetry? This flag specifically
                                 controls if telemetry is sent. Other
                                 --telemetry-* flags set specific values but do
                                 not enable telemetry on their own.    [boolean]
      --telemetry-target         Set the telemetry target (local or gcp).
                                 Overrides settings files.
                                              [string] [choices: "local", "gcp"]
      --telemetry-otlp-endpoint  Set the OTLP endpoint for telemetry. Overrides
                                 environment variables and settings files.
                                                                        [string]
      --telemetry-log-prompts    Enable or disable logging of user prompts for
                                 telemetry. Overrides settings files.  [boolean]
  -c, --checkpointing            Enables checkpointing of file edits
                                                      [boolean] [default: false]
  -v, --version                  Show version number                   [boolean]
  -h, --help                     Show help                             [boolean]
Unknown argument: i
____________________ TestGeminiCLI.test_process_images_urls ____________________

self = <claif_gem.cli.GeminiCLI object at 0x112598a10>, prompt = 'Analyze this'
model = None, temperature = None, system = None, auto_approve = True
yes_mode = True, max_context = None, timeout = None, output_format = 'text'
show_metrics = False, images = 'https://example.com/image.jpg', exec = None
no_retry = False

    def query(
        self,
        prompt: str,
        model: str | None = None,
        temperature: float | None = None,
        system: str | None = None,
        auto_approve: bool = True,
        yes_mode: bool = True,
        max_context: int | None = None,
        timeout: int | None = None,
        output_format: str = "text",
        show_metrics: bool = False,
        images: str | None = None,
        exec: str | None = None,
        no_retry: bool = False,
    ) -> None:
        """
        Executes a query to the Gemini LLM and displays the response.
    
        This method orchestrates the entire query process, including option parsing,
        image processing, asynchronous execution, and result formatting.
    
        Args:
            prompt: The textual prompt to send to the Gemini model.
            model: Optional. The specific Gemini model to use (e.g., 'gemini-pro').
            temperature: Optional. Controls the randomness of the output (0.0 to 1.0).
            system: Optional. A system-level prompt to guide the model's behavior.
            auto_approve: If True, automatically approves actions without user confirmation.
            yes_mode: If True, forces 'yes' to all confirmation prompts.
            max_context: Optional. The maximum context length for the model in tokens.
            timeout: Optional. Maximum time in seconds to wait for a response.
            output_format: The desired format for the output ('text' or 'json').
            show_metrics: If True, displays performance metrics of the query.
            images: Optional. A comma-separated string of local image paths or URLs.
                    URLs will be downloaded to temporary files.
            exec: Optional. Explicit path to the Gemini CLI executable or a command
                  (e.g., 'bun run'). If None, the executable is searched in PATH.
            no_retry: If True, disables all retry attempts for the query.
        """
        # Initialize image paths to None; it will be populated if 'images' argument is provided.
        image_paths: list[str] | None = None
        if images:
            # Process the comma-separated image string into a list of paths.
            image_paths = process_images(images)
    
        # Create a GeminiOptions object from the provided arguments and configuration.
        options: GeminiOptions = GeminiOptions(
            model=model,
            temperature=temperature,
            system_prompt=system,
            auto_approve=auto_approve,
            yes_mode=yes_mode,
            max_context_length=max_context,
            timeout=timeout,
            verbose=self._config.verbose,  # Inherit verbose setting from CLI config
            images=image_paths,
            exec_path=exec,
            no_retry=no_retry,
        )
    
        start_time: float = time.time()  # Record the start time for metrics calculation.
    
        try:
            # Execute the asynchronous query and collect all messages.
>           messages: list[Message] = asyncio.run(self._query_async(prompt, options))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

src/claif_gem/cli.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py:194: in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py:118: in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:686: in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
src/claif_gem/cli.py:150: in _query_async
    async for message in query(prompt, options):
src/claif_gem/client.py:118: in query
    async for message in client.query(prompt, options):
src/claif_gem/client.py:95: in query
    raise e
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <claif_gem.client.GeminiClient object at 0x1125e0710>
prompt = 'Analyze this'
options = GeminiOptions(auto_approve=True, yes_mode=True, cwd=None, system_prompt=None, max_context_length=None, temperature=Non...eout=None, verbose=False, exec_path=None, images=['/tmp/image123.jpg'], retry_count=3, retry_delay=1.0, no_retry=False)

    async def query(
        self,
        prompt: str,
        options: GeminiOptions | None = None,
    ) -> AsyncIterator[Message]:
        """Query Gemini and yield messages with auto-install on missing tools."""
        if options is None:
            options = GeminiOptions()
    
        logger.debug(f"Querying Gemini with prompt: {prompt[:100]}...")
    
        try:
            await self.transport.connect()
    
            async for response in self.transport.send_query(prompt, options):
                if isinstance(response, GeminiMessage):
                    yield response.to_claif_message()
                elif isinstance(response, ResultMessage) and response.error:
                    logger.error(f"Gemini error: {response.message}")
>                   raise Exception(response.message)
E                   Exception: Gemini CLI error: Options:
E                     -m, --model                    Model      [string] [default: "gemini-2.5-pro"]
E                     -p, --prompt                   Prompt. Appended to input on stdin (if any).
E                                                                                           [string]
E                     -s, --sandbox                  Run in sandbox?                       [boolean]
E                         --sandbox-image            Sandbox image URI.                     [string]
E                     -d, --debug                    Run in debug mode?   [boolean] [default: false]
E                     -a, --all_files                Include ALL files in context?
E                                                                         [boolean] [default: false]
E                         --show_memory_usage        Show memory usage in status bar
E                                                                         [boolean] [default: false]
E                     -y, --yolo                     Automatically accept all actions (aka YOLO
E                                                    mode, see
E                                                    https://www.youtube.com/watch?v=xvFZjo5PgG0 for
E                                                    more details)?       [boolean] [default: false]
E                         --telemetry                Enable telemetry? This flag specifically
E                                                    controls if telemetry is sent. Other
E                                                    --telemetry-* flags set specific values but do
E                                                    not enable telemetry on their own.    [boolean]
E                         --telemetry-target         Set the telemetry target (local or gcp).
E                                                    Overrides settings files.
E                                                                 [string] [choices: "local", "gcp"]
E                         --telemetry-otlp-endpoint  Set the OTLP endpoint for telemetry. Overrides
E                                                    environment variables and settings files.
E                                                                                           [string]
E                         --telemetry-log-prompts    Enable or disable logging of user prompts for
E                                                    telemetry. Overrides settings files.  [boolean]
E                     -c, --checkpointing            Enables checkpointing of file edits
E                                                                         [boolean] [default: false]
E                     -v, --version                  Show version number                   [boolean]
E                     -h, --help                     Show help                             [boolean]
E                   Unknown argument: i

src/claif_gem/client.py:58: Exception

During handling of the above exception, another exception occurred:

self = <test_cli_comprehensive.TestGeminiCLI object at 0x1124edb50>
cli = <claif_gem.cli.GeminiCLI object at 0x112598a10>

    def test_process_images_urls(self, cli):
        """Test process_images with URLs."""
        with patch("claif_gem.cli.process_images") as mock_process_images:
            mock_process_images.return_value = ["/tmp/image123.jpg"]
    
>           cli.query("Analyze this", images="https://example.com/image.jpg")

tests/test_cli_comprehensive.py:310: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <claif_gem.cli.GeminiCLI object at 0x112598a10>, prompt = 'Analyze this'
model = None, temperature = None, system = None, auto_approve = True
yes_mode = True, max_context = None, timeout = None, output_format = 'text'
show_metrics = False, images = 'https://example.com/image.jpg', exec = None
no_retry = False

    def query(
        self,
        prompt: str,
        model: str | None = None,
        temperature: float | None = None,
        system: str | None = None,
        auto_approve: bool = True,
        yes_mode: bool = True,
        max_context: int | None = None,
        timeout: int | None = None,
        output_format: str = "text",
        show_metrics: bool = False,
        images: str | None = None,
        exec: str | None = None,
        no_retry: bool = False,
    ) -> None:
        """
        Executes a query to the Gemini LLM and displays the response.
    
        This method orchestrates the entire query process, including option parsing,
        image processing, asynchronous execution, and result formatting.
    
        Args:
            prompt: The textual prompt to send to the Gemini model.
            model: Optional. The specific Gemini model to use (e.g., 'gemini-pro').
            temperature: Optional. Controls the randomness of the output (0.0 to 1.0).
            system: Optional. A system-level prompt to guide the model's behavior.
            auto_approve: If True, automatically approves actions without user confirmation.
            yes_mode: If True, forces 'yes' to all confirmation prompts.
            max_context: Optional. The maximum context length for the model in tokens.
            timeout: Optional. Maximum time in seconds to wait for a response.
            output_format: The desired format for the output ('text' or 'json').
            show_metrics: If True, displays performance metrics of the query.
            images: Optional. A comma-separated string of local image paths or URLs.
                    URLs will be downloaded to temporary files.
            exec: Optional. Explicit path to the Gemini CLI executable or a command
                  (e.g., 'bun run'). If None, the executable is searched in PATH.
            no_retry: If True, disables all retry attempts for the query.
        """
        # Initialize image paths to None; it will be populated if 'images' argument is provided.
        image_paths: list[str] | None = None
        if images:
            # Process the comma-separated image string into a list of paths.
            image_paths = process_images(images)
    
        # Create a GeminiOptions object from the provided arguments and configuration.
        options: GeminiOptions = GeminiOptions(
            model=model,
            temperature=temperature,
            system_prompt=system,
            auto_approve=auto_approve,
            yes_mode=yes_mode,
            max_context_length=max_context,
            timeout=timeout,
            verbose=self._config.verbose,  # Inherit verbose setting from CLI config
            images=image_paths,
            exec_path=exec,
            no_retry=no_retry,
        )
    
        start_time: float = time.time()  # Record the start time for metrics calculation.
    
        try:
            # Execute the asynchronous query and collect all messages.
            messages: list[Message] = asyncio.run(self._query_async(prompt, options))
    
            # Iterate through the received messages and format/display them.
            for message in messages:
                formatted_output: str = format_response(message, output_format)
                _print(formatted_output)
    
            # If requested, calculate and display response metrics.
            if show_metrics:
                duration: float = time.time() - start_time
                metrics: ResponseMetrics = ResponseMetrics(
                    duration=duration,
                    provider=Provider.GEMINI,
                    model=model or "default",  # Use "default" if no specific model was provided.
                )
                _print("\n" + format_metrics(metrics))
    
        except Exception as e:
            # Catch any exceptions during the query process, print an error message,
            # and exit with a non-zero status code to indicate failure.
            _print_error(str(e))
            if self._config.verbose:
                # If verbose mode is enabled, print the full traceback for debugging.
                logger.exception("Full error details for Gemini query failure:")
>           sys.exit(1)
E           SystemExit: 1

src/claif_gem/cli.py:136: SystemExit
---------------------------- Captured stderr setup -----------------------------
2025-07-03 18:14:10.456 | DEBUG    | claif_gem.cli:__init__:46 - Initialized Gemini CLI
----------------------------- Captured stdout call -----------------------------
Error: Gemini CLI error: Options:
  -m, --model                    Model       
  -p, --prompt                   Prompt. Appended to input on stdin (if any).
                                                                        
  -s, --sandbox                  Run in sandbox?                       
      --sandbox-image            Sandbox image URI.                     
  -d, --debug                    Run in debug mode?    
  -a, --all_files                Include ALL files in context?
                                                       
      --show_memory_usage        Show memory usage in status bar
                                                       
  -y, --yolo                     Automatically accept all actions (aka YOLO
                                 mode, see
                                 https://www.youtube.com/watch?v=xvFZjo5PgG0 for
                                 more details)?        
      --telemetry                Enable telemetry? This flag specifically
                                 controls if telemetry is sent. Other
                                 --telemetry-* flags set specific values but do
                                 not enable telemetry on their own.    
      --telemetry-target         Set the telemetry target (local or gcp).
                                 Overrides settings files.
                                               
      --telemetry-otlp-endpoint  Set the OTLP endpoint for telemetry. Overrides
                                 environment variables and settings files.
                                                                        
      --telemetry-log-prompts    Enable or disable logging of user prompts for
                                 telemetry. Overrides settings files.  
  -c, --checkpointing            Enables checkpointing of file edits
                                                       
  -v, --version                  Show version number                   
  -h, --help                     Show help                             
Unknown argument: i
----------------------------- Captured stderr call -----------------------------
2025-07-03 18:14:10.457 | DEBUG    | claif_gem.client:query:48 - Querying Gemini with prompt: Analyze this...
2025-07-03 18:14:10.457 | DEBUG    | claif.install:get_install_location:47 - Using claif install directory: /Users/adam/Library/Application Support/com.twardoch.claif/bin
2025-07-03 18:14:10.458 | DEBUG    | claif.common.utils:inject_claif_bin_to_path:313 - Injected /Users/adam/Library/Application Support/com.twardoch.claif/bin into PATH.
2025-07-03 18:14:10.458 | DEBUG    | claif_gem.transport:send_query:152 - Gemini query attempt 1/3
2025-07-03 18:14:11.369 | ERROR    | claif_gem.client:query:57 - Gemini error: Gemini CLI error: Options:
  -m, --model                    Model      [string] [default: "gemini-2.5-pro"]
  -p, --prompt                   Prompt. Appended to input on stdin (if any).
                                                                        [string]
  -s, --sandbox                  Run in sandbox?                       [boolean]
      --sandbox-image            Sandbox image URI.                     [string]
  -d, --debug                    Run in debug mode?   [boolean] [default: false]
  -a, --all_files                Include ALL files in context?
                                                      [boolean] [default: false]
      --show_memory_usage        Show memory usage in status bar
                                                      [boolean] [default: false]
  -y, --yolo                     Automatically accept all actions (aka YOLO
                                 mode, see
                                 https://www.youtube.com/watch?v=xvFZjo5PgG0 for
                                 more details)?       [boolean] [default: false]
      --telemetry                Enable telemetry? This flag specifically
                                 controls if telemetry is sent. Other
                                 --telemetry-* flags set specific values but do
                                 not enable telemetry on their own.    [boolean]
      --telemetry-target         Set the telemetry target (local or gcp).
                                 Overrides settings files.
                                              [string] [choices: "local", "gcp"]
      --telemetry-otlp-endpoint  Set the OTLP endpoint for telemetry. Overrides
                                 environment variables and settings files.
                                                                        [string]
      --telemetry-log-prompts    Enable or disable logging of user prompts for
                                 telemetry. Overrides settings files.  [boolean]
  -c, --checkpointing            Enables checkpointing of file edits
                                                      [boolean] [default: false]
  -v, --version                  Show version number                   [boolean]
  -h, --help                     Show help                             [boolean]
Unknown argument: i
________________ TestHelperFunctions.test_is_cli_missing_error _________________

self = <test_client_comprehensive.TestHelperFunctions object at 0x1124ef7d0>

    def test_is_cli_missing_error(self):
        """Test CLI missing error detection."""
        # Positive cases
        assert _is_cli_missing_error(Exception("command not found"))
        assert _is_cli_missing_error(Exception("No such file or directory"))
        assert _is_cli_missing_error(Exception("is not recognized as an internal or external command"))
        assert _is_cli_missing_error(Exception("Cannot find gemini"))
        assert _is_cli_missing_error(Exception("gemini not found"))
        assert _is_cli_missing_error(Exception("executable not found"))
        assert _is_cli_missing_error(Exception("Permission denied"))
>       assert _is_cli_missing_error(FileNotFoundError("gemini"))
E       AssertionError: assert False
E        +  where False = _is_cli_missing_error(FileNotFoundError('gemini'))
E        +    where FileNotFoundError('gemini') = FileNotFoundError('gemini')

tests/test_client_comprehensive.py:25: AssertionError
_____________________ TestGeminiClient.test_query_success ______________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________________ TestGeminiClient.test_query_no_options ____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestGeminiClient.test_query_with_error_result _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestGeminiClient.test_query_multiple_messages _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestGeminiClient.test_query_auto_install_on_cli_missing ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestGeminiClient.test_query_auto_install_fails ________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________ TestGeminiClient.test_query_non_cli_error ___________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestGeminiClient.test_query_ensures_disconnect ________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________ TestGeminiClient.test_query_connect_error ___________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________________ TestModuleLevelFunctions.test_query_function _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________ TestModuleLevelFunctions.test_query_function_with_options ___________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________________ TestGeminiTransport.test_send_query_success __________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestGeminiTransport.test_send_query_with_retry ________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____________ TestGeminiTransport.test_send_query_all_retries_fail _____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________________ test_retry_on_quota_exhausted _________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________________ test_retry_on_rate_limit ___________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________________________ test_no_retry_flag ______________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________________ test_max_retries_exceeded ___________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________________ test_non_retryable_error ___________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________________ test_send_query_success ____________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________________ test_build_command_verbose __________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________________ test_build_command_model ___________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________________ test_build_command_temperature ________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________________ test_build_command_system_prompt _______________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________________ test_build_command_max_context_length _____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________________ test_build_command_auto_approve ________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________________________ test_build_command_yes_mode __________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________________ test_send_query_cli_error ___________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________________ test_send_query_json_decode_error _______________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________________ test_disconnect_terminates_process ______________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________________ TestGeminiTransport.test_connect _______________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestGeminiTransport.test_disconnect_no_process ________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________ TestGeminiTransport.test_disconnect_with_process _______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestGeminiTransport.test_disconnect_with_error ________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________________ TestGeminiTransport.test_build_env ______________________

self = <test_transport_comprehensive.TestGeminiTransport object at 0x1125308f0>
transport = <claif_gem.transport.GeminiTransport object at 0x112610b30>

    def test_build_env(self, transport):
        """Test environment variable building."""
>       with patch("claif_gem.transport.inject_claif_bin_to_path") as mock_inject:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_transport_comprehensive.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x1126df860>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'claif_gem.transport' from '/Users/adam/Developer/vcs/github.twardoch/pub/claif-packages/claif_gem/src/claif_gem/transport.py'> does not have the attribute 'inject_claif_bin_to_path'

/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1437: AttributeError
_______________ TestGeminiTransport.test_build_env_import_error ________________

self = <test_transport_comprehensive.TestGeminiTransport object at 0x112530e00>
transport = <claif_gem.transport.GeminiTransport object at 0x112679220>

    def test_build_env_import_error(self, transport):
        """Test environment building when claif import fails."""
>       with patch("claif_gem.transport.inject_claif_bin_to_path", side_effect=ImportError):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_transport_comprehensive.py:155: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1467: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x1126786b0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'claif_gem.transport' from '/Users/adam/Developer/vcs/github.twardoch/pub/claif-packages/claif_gem/src/claif_gem/transport.py'> does not have the attribute 'inject_claif_bin_to_path'

/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/unittest/mock.py:1437: AttributeError
_____________ TestGeminiTransport.test_execute_query_success_json ______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________ TestGeminiTransport.test_execute_query_success_plain_text ___________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________ TestGeminiTransport.test_execute_query_error_non_retryable __________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________ TestGeminiTransport.test_execute_query_error_retryable ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________ TestGeminiTransport.test_execute_query_empty_response _____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________________ TestGeminiTransport.test_send_query_no_retry _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________ TestGeminiTransport.test_send_query_with_retry_success ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____________ TestGeminiTransport.test_send_query_all_retries_fail _____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestGeminiTransport.test_send_query_empty_response_error ___________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________ TestGeminiTransport.test_process_tracking ___________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________ TestGeminiResponse.test_response_creation_minimal _______________

self = <test_types_comprehensive.TestGeminiResponse object at 0x1125808c0>

    def test_response_creation_minimal(self):
        """Test minimal response creation."""
        response = GeminiResponse(content="Response text")
    
>       assert len(response.content) == 1
E       AssertionError: assert 13 == 1
E        +  where 13 = len('Response text')
E        +    where 'Response text' = GeminiResponse(content='Response text', role='assistant', model=None, usage=None, raw_response=None).content

tests/test_types_comprehensive.py:153: AssertionError
________________ TestGeminiResponse.test_response_creation_full ________________

self = <test_types_comprehensive.TestGeminiResponse object at 0x112533860>

    def test_response_creation_full(self):
        """Test full response creation with all fields."""
        usage_data = {"prompt_tokens": 10, "completion_tokens": 20, "total_tokens": 30}
        raw_data = {"id": "123", "object": "chat.completion", "created": 1234567890}
    
        response = GeminiResponse(
            content="Full response", role="assistant", model="gemini-pro", usage=usage_data, raw_response=raw_data
        )
    
>       assert len(response.content) == 1
E       AssertionError: assert 13 == 1
E        +  where 13 = len('Full response')
E        +    where 'Full response' = GeminiResponse(content='Full response', role='assistant', model='gemini-pro', usage={'prompt_tokens': 10, 'completion_tokens': 20, 'total_tokens': 30}, raw_response={'id': '123', 'object': 'chat.completion', 'created': 1234567890}).content

tests/test_types_comprehensive.py:169: AssertionError
============================= slowest 10 durations =============================
1.27s call     tests/test_cli_comprehensive.py::TestGeminiCLI::test_process_images_local_files
0.92s call     tests/test_cli_comprehensive.py::TestGeminiCLI::test_process_images_urls
0.01s call     tests/test_cli_comprehensive.py::TestGeminiCLI::test_status

(7 durations < 0.005s hidden.  Use -vv to show these durations.)
=========================== short test summary info ============================
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_basic - Fai...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_with_all_options
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_json_format
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_with_metrics
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_error_handling
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_query_with_images
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_health_success - ...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_health_failure - ...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_models - assert F...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_config_show - ass...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_install - Attribu...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_install_failure
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_stream - Failed: ...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_benchmark - Faile...
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_process_images_local_files
FAILED tests/test_cli_comprehensive.py::TestGeminiCLI::test_process_images_urls
FAILED tests/test_client_comprehensive.py::TestHelperFunctions::test_is_cli_missing_error
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_success
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_no_options
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_with_error_result
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_multiple_messages
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_auto_install_on_cli_missing
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_auto_install_fails
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_non_cli_error
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_ensures_disconnect
FAILED tests/test_client_comprehensive.py::TestGeminiClient::test_query_connect_error
FAILED tests/test_client_comprehensive.py::TestModuleLevelFunctions::test_query_function
FAILED tests/test_client_comprehensive.py::TestModuleLevelFunctions::test_query_function_with_options
FAILED tests/test_package.py::TestGeminiTransport::test_send_query_success - ...
FAILED tests/test_package.py::TestGeminiTransport::test_send_query_with_retry
FAILED tests/test_package.py::TestGeminiTransport::test_send_query_all_retries_fail
FAILED tests/test_retry_logic.py::test_retry_on_quota_exhausted - Failed: asy...
FAILED tests/test_retry_logic.py::test_retry_on_rate_limit - Failed: async de...
FAILED tests/test_retry_logic.py::test_no_retry_flag - Failed: async def func...
FAILED tests/test_retry_logic.py::test_max_retries_exceeded - Failed: async d...
FAILED tests/test_retry_logic.py::test_non_retryable_error - Failed: async de...
FAILED tests/test_transport.py::test_send_query_success - Failed: async def f...
FAILED tests/test_transport.py::test_build_command_verbose - Failed: async de...
FAILED tests/test_transport.py::test_build_command_model - Failed: async def ...
FAILED tests/test_transport.py::test_build_command_temperature - Failed: asyn...
FAILED tests/test_transport.py::test_build_command_system_prompt - Failed: as...
FAILED tests/test_transport.py::test_build_command_max_context_length - Faile...
FAILED tests/test_transport.py::test_build_command_auto_approve - Failed: asy...
FAILED tests/test_transport.py::test_build_command_yes_mode - Failed: async d...
FAILED tests/test_transport.py::test_send_query_cli_error - Failed: async def...
FAILED tests/test_transport.py::test_send_query_json_decode_error - Failed: a...
FAILED tests/test_transport.py::test_disconnect_terminates_process - Failed: ...
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_connect
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_disconnect_no_process
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_disconnect_with_process
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_disconnect_with_error
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_env
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_build_env_import_error
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_success_json
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_success_plain_text
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_error_non_retryable
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_error_retryable
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_execute_query_empty_response
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_no_retry
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_with_retry_success
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_all_retries_fail
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_send_query_empty_response_error
FAILED tests/test_transport_comprehensive.py::TestGeminiTransport::test_process_tracking
FAILED tests/test_types_comprehensive.py::TestGeminiResponse::test_response_creation_minimal
FAILED tests/test_types_comprehensive.py::TestGeminiResponse::test_response_creation_full
======================== 65 failed, 52 passed in 3.67s =========================
